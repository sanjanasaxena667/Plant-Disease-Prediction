{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "executionInfo": {
     "elapsed": 123439,
     "status": "ok",
     "timestamp": 1736913587973,
     "user": {
      "displayName": "Sanjana Saxena",
      "userId": "05427038380167297565"
     },
     "user_tz": -330
    },
    "id": "7B13EPkUUSuP",
    "outputId": "8c6556ef-6fd4-4c37-f6ae-44086ba001b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please upload your kaggle.json file:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-67a6a420-82ab-403c-8e01-368841a69b08\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-67a6a420-82ab-403c-8e01-368841a69b08\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n",
      "ref                                                            title                                             size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
      "-------------------------------------------------------------  -----------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
      "anandshaw2001/netflix-movies-and-tv-shows                      Netflix Movies and TV Shows                        1MB  2025-01-03 10:33:01           3152         89  1.0              \n",
      "harry5760/food-impact-on-indians                               Food impact on Indians                           316KB  2025-01-11 09:57:18            624         23  1.0              \n",
      "stealthtechnologies/predict-student-performance-dataset        Predict Student Performance                       12KB  2024-12-26 12:57:04           3893         88  1.0              \n",
      "sebastianwillmann/beverage-sales                               Beverage Sales                                   119MB  2025-01-02 21:00:53           1138         23  1.0              \n",
      "ankushpanday1/heart-attack-in-youth-vs-adults-in-indonesia     Heart Attack in Youth vs Adults in Indonesia       4MB  2025-01-09 14:35:59            585         30  1.0              \n",
      "ankushpanday1/heart-attack-in-youth-vs-adult-in-germany        Heart Attack in Youth Vs Adult in Germany          6MB  2025-01-08 14:33:17           1275         33  1.0              \n",
      "anandshaw2001/mobile-apps-screentime-analysis                  Mobile Apps ScreenTime Analysis                    2KB  2024-12-31 18:20:51           1893         47  1.0              \n",
      "suvroo/credit-card-behaviour-score                             Credit Card Behaviour Score                       70MB  2025-01-10 16:14:49            666         31  1.0              \n",
      "akashsharma0105/phone-usage-in-india                           Phone Usage in India                             444KB  2025-01-11 10:06:50            664         32  1.0              \n",
      "yamaerenay/spotify-dataset-1921-2020-160k-tracks               Spotify Dataset 1921-2020, 160k+ Tracks           16MB  2025-01-06 21:27:40           1020         27  1.0              \n",
      "prajwaldongre/global-financial-giants-by-revenue-2024          Global Financial Giants by Revenue 2024            2KB  2025-01-08 07:07:19            868         26  1.0              \n",
      "solomonameh/spotify-music-dataset                              Spotify Music Dataset                            573KB  2025-01-07 06:51:01           1290         23  0.9411765        \n",
      "ankushpanday1/heart-attack-risk-in-youth-vs-adult-in-pakistan  Heart Attack Risk in Youth Vs Adult in Pakistan    9MB  2025-01-10 15:22:34            396         22  1.0              \n",
      "umerhaddii/apple-stock-data-2025                               Apple Stock Data 2025                            301KB  2025-01-03 16:47:04           1448         50  1.0              \n",
      "oktayrdeki/heart-disease                                       Heart Disease                                    568KB  2024-12-29 13:26:49           2487         44  1.0              \n",
      "taweilo/wine-quality-dataset-balanced-classification           Wine Quality dataset - Classification            377KB  2025-01-07 04:13:51            907         24  1.0              \n",
      "ajinilpatel/energy-consumption-prediction                      Energy consumption prediction                    240KB  2025-01-10 04:41:55            645         28  1.0              \n",
      "hopesb/student-depression-dataset                              Student Depression Dataset.                      454KB  2024-11-22 17:56:03          19637        268  1.0              \n",
      "arifmia/heart-attack-risk-dataset                              heart attack risk dataset                        992KB  2025-01-08 19:24:30           1545         26  0.7058824        \n",
      "ankushpanday1/heart-attack-in-youth-vs-adult-in-france         Heart Attack in Youth VS Adult in France           8MB  2025-01-07 17:13:59           1104         37  1.0              \n",
      "Dataset URL: https://www.kaggle.com/datasets/emmarex/plantdisease\n",
      "License(s): unknown\n",
      "Downloading plantdisease.zip to /content\n",
      "100% 657M/658M [00:32<00:00, 21.3MB/s]\n",
      "100% 658M/658M [00:32<00:00, 21.5MB/s]\n",
      "Contents of the current directory:\n",
      "['.config', 'PlantVillage', 'plantvillage', 'sample_data']\n",
      "Contents of PlantVillage:\n",
      "['Tomato_Bacterial_spot', 'Potato___Early_blight', 'Tomato_Septoria_leaf_spot', 'Potato___Late_blight', 'Pepper__bell___healthy', 'Tomato__Tomato_YellowLeaf__Curl_Virus', 'Potato___healthy', 'Tomato_healthy', 'Tomato__Tomato_mosaic_virus', 'Tomato_Leaf_Mold', 'Tomato__Target_Spot', 'Tomato_Late_blight', 'Pepper__bell___Bacterial_spot', 'Tomato_Spider_mites_Two_spotted_spider_mite', 'Tomato_Early_blight']\n"
     ]
    }
   ],
   "source": [
    "# Install the Kaggle library\n",
    "!pip install kaggle --quiet\n",
    "\n",
    "from google.colab import files\n",
    "print(\"Please upload your kaggle.json file:\")\n",
    "files.upload()\n",
    "\n",
    "# Move the kaggle.json file to the .kaggle directory\n",
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Verify Kaggle installation and authentication\n",
    "!kaggle datasets list\n",
    "\n",
    "# Download the dataset\n",
    "!kaggle datasets download -d emmarex/plantdisease --unzip\n",
    "\n",
    "# Verify the dataset is downloaded\n",
    "import os\n",
    "print(\"Contents of the current directory:\")\n",
    "print(os.listdir(\".\"))\n",
    "\n",
    "# Check the contents of the downloaded dataset folder\n",
    "dataset_folder = \"PlantVillage\"  # Adjust if the folder name is different\n",
    "if os.path.exists(dataset_folder):\n",
    "    print(f\"Contents of {dataset_folder}:\")\n",
    "    print(os.listdir(dataset_folder))\n",
    "else:\n",
    "    print(f\"Folder '{dataset_folder}' not found. Check the directory listing above.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3Ut-JVEk3uP"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIkM7j6sceHc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# import data handling tools\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler , MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 1374,
     "status": "error",
     "timestamp": 1736882154035,
     "user": {
      "displayName": "Sanjana Saxena",
      "userId": "05427038380167297565"
     },
     "user_tz": -330
    },
    "id": "SoCkdAsAceHe",
    "outputId": "8cc7a067-729e-4ae3-db32-e6508626fa42"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/PlantVillage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e13e4592edbe>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Iterate through the dataset directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mclass_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/PlantVillage'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the dataset path and selected classes\n",
    "dataset_path = '/content/PlantVillage'\n",
    "selected_classes = [\n",
    "    'Pepper__bell___Bacterial_spot',\n",
    "    'Pepper__bell___healthy',\n",
    "    'Potato___healthy',\n",
    "    'Potato___Late_blight',\n",
    "    'Tomato__Target_Spot',  # Corrected class name\n",
    "    'Tomato___healthy'\n",
    "]\n",
    "\n",
    "# Initialize data and labels lists\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through the dataset directory\n",
    "for class_name in os.listdir(dataset_path):\n",
    "    if class_name in selected_classes:\n",
    "        class_dir = os.path.join(dataset_path, class_name)\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            data.append(img_path)\n",
    "            labels.append(class_name)\n",
    "\n",
    "# Create a DataFrame to organize the data\n",
    "df = pd.DataFrame({'data': data, 'label': labels})\n",
    "\n",
    "# Check class distribution\n",
    "class_counts = df['label'].value_counts()\n",
    "print(\"Class Distribution:\\n\", class_counts)\n",
    "\n",
    "# Plot histogram to visualize class imbalance\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 479,
     "status": "ok",
     "timestamp": 1736658063585,
     "user": {
      "displayName": "Sanjana Saxena",
      "userId": "05427038380167297565"
     },
     "user_tz": -330
    },
    "id": "knhesuLTceHf",
    "outputId": "4c9b3493-ee29-4d7f-afe2-9465b92b96cc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5031,\n  \"fields\": [\n    {\n      \"column\": \"data\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5031,\n        \"samples\": [\n          \"/content/PlantVillage/Tomato__Target_Spot/13eec704-81e1-46ff-b316-f9271fc39d3b___Com.G_TgS_FL 1114.JPG\",\n          \"/content/PlantVillage/Pepper__bell___Bacterial_spot/3e71a4e5-32e9-404e-815c-95208f7a79fd___JR_B.Spot 3258.JPG\",\n          \"/content/PlantVillage/Pepper__bell___healthy/4a5268b4-1614-4ea5-b973-72126fbfd7f2___JR_HL 8102.JPG\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Potato___Late_blight\",\n          \"Tomato__Target_Spot\",\n          \"Pepper__bell___Bacterial_spot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ed9872c6-51c9-4363-8fa9-f9d871b0a679\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/content/PlantVillage/Potato___healthy/e34e563...</td>\n",
       "      <td>Potato___healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/content/PlantVillage/Potato___healthy/799b10e...</td>\n",
       "      <td>Potato___healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/content/PlantVillage/Potato___healthy/dca8ac5...</td>\n",
       "      <td>Potato___healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/content/PlantVillage/Potato___healthy/5fcbde8...</td>\n",
       "      <td>Potato___healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/content/PlantVillage/Potato___healthy/54f8631...</td>\n",
       "      <td>Potato___healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5026</th>\n",
       "      <td>/content/PlantVillage/Tomato__Target_Spot/70f5...</td>\n",
       "      <td>Tomato__Target_Spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5027</th>\n",
       "      <td>/content/PlantVillage/Tomato__Target_Spot/420d...</td>\n",
       "      <td>Tomato__Target_Spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5028</th>\n",
       "      <td>/content/PlantVillage/Tomato__Target_Spot/b320...</td>\n",
       "      <td>Tomato__Target_Spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5029</th>\n",
       "      <td>/content/PlantVillage/Tomato__Target_Spot/dfce...</td>\n",
       "      <td>Tomato__Target_Spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030</th>\n",
       "      <td>/content/PlantVillage/Tomato__Target_Spot/9af0...</td>\n",
       "      <td>Tomato__Target_Spot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5031 rows Ã— 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed9872c6-51c9-4363-8fa9-f9d871b0a679')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ed9872c6-51c9-4363-8fa9-f9d871b0a679 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ed9872c6-51c9-4363-8fa9-f9d871b0a679');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-bfc89b52-1d24-4e21-848e-981c6e674e74\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bfc89b52-1d24-4e21-848e-981c6e674e74')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-bfc89b52-1d24-4e21-848e-981c6e674e74 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_61393fb6-2e7b-4543-a984-7cb7572323c5\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_61393fb6-2e7b-4543-a984-7cb7572323c5 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                   data                label\n",
       "0     /content/PlantVillage/Potato___healthy/e34e563...     Potato___healthy\n",
       "1     /content/PlantVillage/Potato___healthy/799b10e...     Potato___healthy\n",
       "2     /content/PlantVillage/Potato___healthy/dca8ac5...     Potato___healthy\n",
       "3     /content/PlantVillage/Potato___healthy/5fcbde8...     Potato___healthy\n",
       "4     /content/PlantVillage/Potato___healthy/54f8631...     Potato___healthy\n",
       "...                                                 ...                  ...\n",
       "5026  /content/PlantVillage/Tomato__Target_Spot/70f5...  Tomato__Target_Spot\n",
       "5027  /content/PlantVillage/Tomato__Target_Spot/420d...  Tomato__Target_Spot\n",
       "5028  /content/PlantVillage/Tomato__Target_Spot/b320...  Tomato__Target_Spot\n",
       "5029  /content/PlantVillage/Tomato__Target_Spot/dfce...  Tomato__Target_Spot\n",
       "5030  /content/PlantVillage/Tomato__Target_Spot/9af0...  Tomato__Target_Spot\n",
       "\n",
       "[5031 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1736658067952,
     "user": {
      "displayName": "Sanjana Saxena",
      "userId": "05427038380167297565"
     },
     "user_tz": -330
    },
    "id": "NdibqoCuIPwa",
    "outputId": "a34ad227-267e-48ad-bf0f-01224fe60169"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
       "      pre.function-repr-contents {\n",
       "        overflow-x: auto;\n",
       "        padding: 8px 12px;\n",
       "        max-height: 500px;\n",
       "      }\n",
       "\n",
       "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
       "        cursor: pointer;\n",
       "        max-height: 100px;\n",
       "      }\n",
       "    </style>\n",
       "    <pre style=\"white-space: initial; background:\n",
       "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
       "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.generic.NDFrame.describe</b><br/>def describe(percentiles=None, include=None, exclude=None) -&gt; Self</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py</a>Generate descriptive statistics.\n",
       "\n",
       "Descriptive statistics include those that summarize the central\n",
       "tendency, dispersion and shape of a\n",
       "dataset&#x27;s distribution, excluding ``NaN`` values.\n",
       "\n",
       "Analyzes both numeric and object series, as well\n",
       "as ``DataFrame`` column sets of mixed data types. The output\n",
       "will vary depending on what is provided. Refer to the notes\n",
       "below for more detail.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "percentiles : list-like of numbers, optional\n",
       "    The percentiles to include in the output. All should\n",
       "    fall between 0 and 1. The default is\n",
       "    ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
       "    75th percentiles.\n",
       "include : &#x27;all&#x27;, list-like of dtypes or None (default), optional\n",
       "    A white list of data types to include in the result. Ignored\n",
       "    for ``Series``. Here are the options:\n",
       "\n",
       "    - &#x27;all&#x27; : All columns of the input will be included in the output.\n",
       "    - A list-like of dtypes : Limits the results to the\n",
       "      provided data types.\n",
       "      To limit the result to numeric types submit\n",
       "      ``numpy.number``. To limit it instead to object columns submit\n",
       "      the ``numpy.object`` data type. Strings\n",
       "      can also be used in the style of\n",
       "      ``select_dtypes`` (e.g. ``df.describe(include=[&#x27;O&#x27;])``). To\n",
       "      select pandas categorical columns, use ``&#x27;category&#x27;``\n",
       "    - None (default) : The result will include all numeric columns.\n",
       "exclude : list-like of dtypes or None (default), optional,\n",
       "    A black list of data types to omit from the result. Ignored\n",
       "    for ``Series``. Here are the options:\n",
       "\n",
       "    - A list-like of dtypes : Excludes the provided data types\n",
       "      from the result. To exclude numeric types submit\n",
       "      ``numpy.number``. To exclude object columns submit the data\n",
       "      type ``numpy.object``. Strings can also be used in the style of\n",
       "      ``select_dtypes`` (e.g. ``df.describe(exclude=[&#x27;O&#x27;])``). To\n",
       "      exclude pandas categorical columns, use ``&#x27;category&#x27;``\n",
       "    - None (default) : The result will exclude nothing.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "Series or DataFrame\n",
       "    Summary statistics of the Series or Dataframe provided.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.count: Count number of non-NA/null observations.\n",
       "DataFrame.max: Maximum of the values in the object.\n",
       "DataFrame.min: Minimum of the values in the object.\n",
       "DataFrame.mean: Mean of the values.\n",
       "DataFrame.std: Standard deviation of the observations.\n",
       "DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
       "    columns based on their dtype.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "For numeric data, the result&#x27;s index will include ``count``,\n",
       "``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
       "upper percentiles. By default the lower percentile is ``25`` and the\n",
       "upper percentile is ``75``. The ``50`` percentile is the\n",
       "same as the median.\n",
       "\n",
       "For object data (e.g. strings or timestamps), the result&#x27;s index\n",
       "will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
       "is the most common value. The ``freq`` is the most common value&#x27;s\n",
       "frequency. Timestamps also include the ``first`` and ``last`` items.\n",
       "\n",
       "If multiple object values have the highest count, then the\n",
       "``count`` and ``top`` results will be arbitrarily chosen from\n",
       "among those with the highest count.\n",
       "\n",
       "For mixed data types provided via a ``DataFrame``, the default is to\n",
       "return only an analysis of numeric columns. If the dataframe consists\n",
       "only of object and categorical data without any numeric columns, the\n",
       "default is to return an analysis of both the object and categorical\n",
       "columns. If ``include=&#x27;all&#x27;`` is provided as an option, the result\n",
       "will include a union of attributes of each type.\n",
       "\n",
       "The `include` and `exclude` parameters can be used to limit\n",
       "which columns in a ``DataFrame`` are analyzed for the output.\n",
       "The parameters are ignored when analyzing a ``Series``.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Describing a numeric ``Series``.\n",
       "\n",
       "&gt;&gt;&gt; s = pd.Series([1, 2, 3])\n",
       "&gt;&gt;&gt; s.describe()\n",
       "count    3.0\n",
       "mean     2.0\n",
       "std      1.0\n",
       "min      1.0\n",
       "25%      1.5\n",
       "50%      2.0\n",
       "75%      2.5\n",
       "max      3.0\n",
       "dtype: float64\n",
       "\n",
       "Describing a categorical ``Series``.\n",
       "\n",
       "&gt;&gt;&gt; s = pd.Series([&#x27;a&#x27;, &#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
       "&gt;&gt;&gt; s.describe()\n",
       "count     4\n",
       "unique    3\n",
       "top       a\n",
       "freq      2\n",
       "dtype: object\n",
       "\n",
       "Describing a timestamp ``Series``.\n",
       "\n",
       "&gt;&gt;&gt; s = pd.Series([\n",
       "...     np.datetime64(&quot;2000-01-01&quot;),\n",
       "...     np.datetime64(&quot;2010-01-01&quot;),\n",
       "...     np.datetime64(&quot;2010-01-01&quot;)\n",
       "... ])\n",
       "&gt;&gt;&gt; s.describe()\n",
       "count                      3\n",
       "mean     2006-09-01 08:00:00\n",
       "min      2000-01-01 00:00:00\n",
       "25%      2004-12-31 12:00:00\n",
       "50%      2010-01-01 00:00:00\n",
       "75%      2010-01-01 00:00:00\n",
       "max      2010-01-01 00:00:00\n",
       "dtype: object\n",
       "\n",
       "Describing a ``DataFrame``. By default only numeric fields\n",
       "are returned.\n",
       "\n",
       "&gt;&gt;&gt; df = pd.DataFrame({&#x27;categorical&#x27;: pd.Categorical([&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;]),\n",
       "...                    &#x27;numeric&#x27;: [1, 2, 3],\n",
       "...                    &#x27;object&#x27;: [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]\n",
       "...                    })\n",
       "&gt;&gt;&gt; df.describe()\n",
       "       numeric\n",
       "count      3.0\n",
       "mean       2.0\n",
       "std        1.0\n",
       "min        1.0\n",
       "25%        1.5\n",
       "50%        2.0\n",
       "75%        2.5\n",
       "max        3.0\n",
       "\n",
       "Describing all columns of a ``DataFrame`` regardless of data type.\n",
       "\n",
       "&gt;&gt;&gt; df.describe(include=&#x27;all&#x27;)  # doctest: +SKIP\n",
       "       categorical  numeric object\n",
       "count            3      3.0      3\n",
       "unique           3      NaN      3\n",
       "top              f      NaN      a\n",
       "freq             1      NaN      1\n",
       "mean           NaN      2.0    NaN\n",
       "std            NaN      1.0    NaN\n",
       "min            NaN      1.0    NaN\n",
       "25%            NaN      1.5    NaN\n",
       "50%            NaN      2.0    NaN\n",
       "75%            NaN      2.5    NaN\n",
       "max            NaN      3.0    NaN\n",
       "\n",
       "Describing a column from a ``DataFrame`` by accessing it as\n",
       "an attribute.\n",
       "\n",
       "&gt;&gt;&gt; df.numeric.describe()\n",
       "count    3.0\n",
       "mean     2.0\n",
       "std      1.0\n",
       "min      1.0\n",
       "25%      1.5\n",
       "50%      2.0\n",
       "75%      2.5\n",
       "max      3.0\n",
       "Name: numeric, dtype: float64\n",
       "\n",
       "Including only numeric columns in a ``DataFrame`` description.\n",
       "\n",
       "&gt;&gt;&gt; df.describe(include=[np.number])\n",
       "       numeric\n",
       "count      3.0\n",
       "mean       2.0\n",
       "std        1.0\n",
       "min        1.0\n",
       "25%        1.5\n",
       "50%        2.0\n",
       "75%        2.5\n",
       "max        3.0\n",
       "\n",
       "Including only string columns in a ``DataFrame`` description.\n",
       "\n",
       "&gt;&gt;&gt; df.describe(include=[object])  # doctest: +SKIP\n",
       "       object\n",
       "count       3\n",
       "unique      3\n",
       "top         a\n",
       "freq        1\n",
       "\n",
       "Including only categorical columns from a ``DataFrame`` description.\n",
       "\n",
       "&gt;&gt;&gt; df.describe(include=[&#x27;category&#x27;])\n",
       "       categorical\n",
       "count            3\n",
       "unique           3\n",
       "top              d\n",
       "freq             1\n",
       "\n",
       "Excluding numeric columns from a ``DataFrame`` description.\n",
       "\n",
       "&gt;&gt;&gt; df.describe(exclude=[np.number])  # doctest: +SKIP\n",
       "       categorical object\n",
       "count            3      3\n",
       "unique           3      3\n",
       "top              f      a\n",
       "freq             1      1\n",
       "\n",
       "Excluding object columns from a ``DataFrame`` description.\n",
       "\n",
       "&gt;&gt;&gt; df.describe(exclude=[object])  # doctest: +SKIP\n",
       "       categorical  numeric\n",
       "count            3      3.0\n",
       "unique           3      NaN\n",
       "top              f      NaN\n",
       "freq             1      NaN\n",
       "mean           NaN      2.0\n",
       "std            NaN      1.0\n",
       "min            NaN      1.0\n",
       "25%            NaN      1.5\n",
       "50%            NaN      2.0\n",
       "75%            NaN      2.5\n",
       "max            NaN      3.0</pre>\n",
       "      <script>\n",
       "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
       "        for (const element of document.querySelectorAll('.filepath')) {\n",
       "          element.style.display = 'block'\n",
       "          element.onclick = (event) => {\n",
       "            event.preventDefault();\n",
       "            event.stopPropagation();\n",
       "            google.colab.files.view(element.textContent, 11734);\n",
       "          };\n",
       "        }\n",
       "      }\n",
       "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
       "        element.onclick = (event) => {\n",
       "          event.preventDefault();\n",
       "          event.stopPropagation();\n",
       "          element.classList.toggle('function-repr-contents-collapsed');\n",
       "        };\n",
       "      }\n",
       "      </script>\n",
       "      </div>"
      ],
      "text/plain": [
       "<bound method NDFrame.describe of                                                    data                label\n",
       "0     /content/PlantVillage/Potato___healthy/e34e563...     Potato___healthy\n",
       "1     /content/PlantVillage/Potato___healthy/799b10e...     Potato___healthy\n",
       "2     /content/PlantVillage/Potato___healthy/dca8ac5...     Potato___healthy\n",
       "3     /content/PlantVillage/Potato___healthy/5fcbde8...     Potato___healthy\n",
       "4     /content/PlantVillage/Potato___healthy/54f8631...     Potato___healthy\n",
       "...                                                 ...                  ...\n",
       "5026  /content/PlantVillage/Tomato__Target_Spot/70f5...  Tomato__Target_Spot\n",
       "5027  /content/PlantVillage/Tomato__Target_Spot/420d...  Tomato__Target_Spot\n",
       "5028  /content/PlantVillage/Tomato__Target_Spot/b320...  Tomato__Target_Spot\n",
       "5029  /content/PlantVillage/Tomato__Target_Spot/dfce...  Tomato__Target_Spot\n",
       "5030  /content/PlantVillage/Tomato__Target_Spot/9af0...  Tomato__Target_Spot\n",
       "\n",
       "[5031 rows x 2 columns]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89qnZF1IzjR3"
   },
   "source": [
    "CNN ARCHITECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MA7RX1c2zmOZ"
   },
   "source": [
    "VGG16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 391467,
     "status": "ok",
     "timestamp": 1736658462408,
     "user": {
      "displayName": "Sanjana Saxena",
      "userId": "05427038380167297565"
     },
     "user_tz": -330
    },
    "id": "d-cSG6KB-5HS",
    "outputId": "d82a03af-50df-4f36-edc1-88280b8fdcbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 706ms/step - accuracy: 0.5830 - loss: 2.0140 - val_accuracy: 0.8769 - val_loss: 0.3207\n",
      "Epoch 2/10\n",
      "\u001b[1m  1/125\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m14s\u001b[0m 119ms/step - accuracy: 0.8438 - loss: 0.5246"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 111ms/step - accuracy: 0.8438 - loss: 0.5246\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 408ms/step - accuracy: 0.7866 - loss: 0.5699 - val_accuracy: 0.9017 - val_loss: 0.2571\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132us/step - accuracy: 0.8125 - loss: 0.4662 \n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 412ms/step - accuracy: 0.8321 - loss: 0.4606 - val_accuracy: 0.8997 - val_loss: 0.2254\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103us/step - accuracy: 0.8438 - loss: 0.5054 \n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 410ms/step - accuracy: 0.8405 - loss: 0.4190 - val_accuracy: 0.8868 - val_loss: 0.2519\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111us/step - accuracy: 0.9375 - loss: 0.1819 \n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 409ms/step - accuracy: 0.8474 - loss: 0.3838 - val_accuracy: 0.9096 - val_loss: 0.2121\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100us/step - accuracy: 0.8750 - loss: 0.4108 \n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 409ms/step - accuracy: 0.8964 - loss: 0.2159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 90.76%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# # Load the data\n",
    "# #df = pd.DataFrame({\n",
    "#     'data': [...],  # Replace with the list of image paths\n",
    "#     'label': [...]  # Replace with the corresponding labels\n",
    "# })\n",
    "\n",
    "# Preprocessing\n",
    "image_size = (224, 224)  # VGG16 input size\n",
    "classes = df['label'].unique()\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['encoded_label'] = label_encoder.fit_transform(df['label'])\n",
    "num_classes = len(classes)\n",
    "\n",
    "# # One-hot encode the labels\n",
    "# one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "# labels = one_hot_encoder.fit_transform(df['encoded_label'].values.reshape(-1, 1))\n",
    "\n",
    "# Load and preprocess images\n",
    "def preprocess_images(image_paths):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = load_img(path, target_size=image_size)\n",
    "        img = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Split the data\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    df['data'], df['encoded_label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_images = preprocess_images(train_paths)\n",
    "val_images = preprocess_images(val_paths)\n",
    "\n",
    "# Build the model\n",
    "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in vgg_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers for classification\n",
    "model = Sequential([\n",
    "    vgg_base,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "history = model.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
    "    validation_data=(val_images, val_labels),\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_images) // batch_size,\n",
    "    validation_steps=len(val_images) // batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_images, val_labels)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# # Save the model\n",
    "model.save('vgg16_plant_disease_model.h5')\n",
    "# output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wy0I1VJd5JK0"
   },
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 593171,
     "status": "ok",
     "timestamp": 1736660209844,
     "user": {
      "displayName": "Sanjana Saxena",
      "userId": "05427038380167297565"
     },
     "user_tz": -330
    },
    "id": "uft1RQ0I44Zj",
    "outputId": "82cb1891-89e1-42f5-9399-af213ab6adb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 511ms/step - accuracy: 0.2695 - loss: 1.6029 - val_accuracy: 0.3575 - val_loss: 1.4347\n",
      "Epoch 2/15\n",
      "\u001b[1m  1/125\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.3438 - loss: 1.4445"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.3438 - loss: 1.4445\n",
      "Epoch 3/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 387ms/step - accuracy: 0.3345 - loss: 1.4276 - val_accuracy: 0.4091 - val_loss: 1.3748\n",
      "Epoch 4/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184us/step - accuracy: 0.2188 - loss: 1.5411\n",
      "Epoch 5/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 381ms/step - accuracy: 0.3389 - loss: 1.4222 - val_accuracy: 0.4717 - val_loss: 1.3728\n",
      "Epoch 6/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184us/step - accuracy: 0.3125 - loss: 1.3687\n",
      "Epoch 7/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 387ms/step - accuracy: 0.3574 - loss: 1.3886 - val_accuracy: 0.4379 - val_loss: 1.3431\n",
      "Epoch 8/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168us/step - accuracy: 0.3125 - loss: 1.4131\n",
      "Epoch 9/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 384ms/step - accuracy: 0.3830 - loss: 1.3659 - val_accuracy: 0.5074 - val_loss: 1.2883\n",
      "Epoch 10/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226us/step - accuracy: 0.2812 - loss: 1.4345\n",
      "Epoch 11/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 378ms/step - accuracy: 0.4046 - loss: 1.3443 - val_accuracy: 0.5492 - val_loss: 1.2460\n",
      "Epoch 12/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178us/step - accuracy: 0.4688 - loss: 1.4485\n",
      "Epoch 13/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 390ms/step - accuracy: 0.4142 - loss: 1.3392 - val_accuracy: 0.5829 - val_loss: 1.2176\n",
      "Epoch 14/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190us/step - accuracy: 0.4688 - loss: 1.2038\n",
      "Epoch 15/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 379ms/step - accuracy: 0.4251 - loss: 1.3071 - val_accuracy: 0.5919 - val_loss: 1.1814\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 177ms/step - accuracy: 0.5911 - loss: 1.1991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 59.19%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Preprocessing\n",
    "image_size = (224, 224)  # Input size for ResNet50\n",
    "classes = df['label'].unique()\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['encoded_label'] = label_encoder.fit_transform(df['label'])\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Load and preprocess images\n",
    "def preprocess_images(image_paths):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = load_img(path, target_size=image_size)\n",
    "        img = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Split the data\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    df['data'], df['encoded_label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_images = preprocess_images(train_paths)\n",
    "val_images = preprocess_images(val_paths)\n",
    "\n",
    "# Build the model using ResNet50\n",
    "resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in resnet_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers for classification\n",
    "model = Sequential([\n",
    "    resnet_base,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "history = model.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
    "    validation_data=(val_images, val_labels),\n",
    "    epochs=15,\n",
    "    steps_per_epoch=len(train_images) // batch_size,\n",
    "    validation_steps=len(val_images) // batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_images, val_labels)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save the model\n",
    "model.save('resnet_plant_disease_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOnNvfLssOoV"
   },
   "source": [
    "efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 682439,
     "status": "ok",
     "timestamp": 1736660992434,
     "user": {
      "displayName": "Sanjana Saxena",
      "userId": "05427038380167297565"
     },
     "user_tz": -330
    },
    "id": "aXsGjJIKsMSo",
    "outputId": "154e17a3-008a-45e1-ec49-5d8aa26568eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 596ms/step - accuracy: 0.2748 - loss: 1.4960 - val_accuracy: 0.2751 - val_loss: 1.4866\n",
      "Epoch 2/15\n",
      "\u001b[1m  1/125\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.3750 - loss: 1.4294"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.3750 - loss: 1.4294\n",
      "Epoch 3/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 351ms/step - accuracy: 0.2943 - loss: 1.4620 - val_accuracy: 0.2781 - val_loss: 1.4867\n",
      "Epoch 4/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149us/step - accuracy: 0.2188 - loss: 1.4287\n",
      "Epoch 5/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 356ms/step - accuracy: 0.2880 - loss: 1.4690 - val_accuracy: 0.2751 - val_loss: 1.4922\n",
      "Epoch 6/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.3125 - loss: 1.4749\n",
      "Epoch 7/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 348ms/step - accuracy: 0.2956 - loss: 1.4685 - val_accuracy: 0.2751 - val_loss: 1.4871\n",
      "Epoch 8/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156us/step - accuracy: 0.2812 - loss: 1.4778\n",
      "Epoch 9/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 347ms/step - accuracy: 0.2867 - loss: 1.4640 - val_accuracy: 0.2781 - val_loss: 1.4885\n",
      "Epoch 10/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150us/step - accuracy: 0.1875 - loss: 1.6761\n",
      "Epoch 11/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 348ms/step - accuracy: 0.2868 - loss: 1.4735 - val_accuracy: 0.2751 - val_loss: 1.4872\n",
      "Epoch 12/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182us/step - accuracy: 0.1875 - loss: 1.4305\n",
      "Epoch 13/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 354ms/step - accuracy: 0.3030 - loss: 1.4673 - val_accuracy: 0.2751 - val_loss: 1.4848\n",
      "Epoch 14/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3750 - loss: 1.3784 \n",
      "Epoch 15/15\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 353ms/step - accuracy: 0.2960 - loss: 1.4633 - val_accuracy: 0.2751 - val_loss: 1.4849\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247ms/step - accuracy: 0.2632 - loss: 1.4950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 27.51%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Preprocessing\n",
    "image_size = (224, 224)  # Input size for EfficientNetB0\n",
    "classes = df['label'].unique()\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['encoded_label'] = label_encoder.fit_transform(df['label'])\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Load and preprocess images\n",
    "def preprocess_images(image_paths):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = load_img(path, target_size=image_size)\n",
    "        img = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Split the data\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    df['data'], df['encoded_label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_images = preprocess_images(train_paths)\n",
    "val_images = preprocess_images(val_paths)\n",
    "\n",
    "# Build the model using EfficientNetB0\n",
    "efficientnet_base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in efficientnet_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers for classification\n",
    "model = Sequential([\n",
    "    efficientnet_base,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "history = model.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
    "    validation_data=(val_images, val_labels),\n",
    "    epochs=15,\n",
    "    steps_per_epoch=len(train_images) // batch_size,\n",
    "    validation_steps=len(val_images) // batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_images, val_labels)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save the model\n",
    "model.save('efficientnet_plant_disease_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3786,
     "status": "ok",
     "timestamp": 1736660997901,
     "user": {
      "displayName": "Sanjana Saxena",
      "userId": "05427038380167297565"
     },
     "user_tz": -330
    },
    "id": "yZSvFHxG1Vwt",
    "outputId": "4083eb04-7b7f-4869-b6ae-536ffd0b56a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.59-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.59-py3-none-any.whl (906 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m906.8/906.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: ultralytics-thop, ultralytics\n",
      "Successfully installed ultralytics-8.3.59 ultralytics-thop-2.0.13\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 70909,
     "sourceId": 150545,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
